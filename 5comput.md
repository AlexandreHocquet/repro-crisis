TL;DR
-----
Comment situer la reproductibilité computationnelle dans ce panorama ? En quoi est elle moins visible ? En quoi elle est différente ou semblable ? Est elle en période de crise ?

Expérimental - Statistique - Computationnel
-------------------------------------------
la reproductibilité computationnelle est ce qu'il nous intéresse ici. D'une part, la narration de la crise (telle que cette dernière apparait dans les médias a tendance à l'invisibiliser sous le flot de la crise statistique (voir le paragraphe 4). Si on distingue trois domaines différents dans laquelle la reproductibilité s'exprime (bien que les trois soient entremêlés) expérimental / statistique / computationnel, alors le statistique est la vedette de la crise. D'ailleurs, dans sa catégorisation, Leonelli a tendance à 1) confondre computationnel et statistique , 2) réduire le computationnel au traitement de données. 
Le statistique a tendance à être plus impliqué dans les domaines les plus médiatiques  (essais cliniques et psychologie). Le statistique est plus utilisé par des non-experts et il est plus facile à dramatiser, donc à médiatiser. L'apparition médiatique d'experts en "méta-science" comme Ioannidis, surfant sur cette vague de la crise de la reproductibilité en atteste.
La reproductibilité expérimentale est historiquement apparue en premier (voir chapitre 1). Les différents aspects qui la caractérisent dépendent de chaque domaine scientifique. Il est donc difficile d'en esquisser des principes généraux. Le philosophe John Norton argumente même qu'il n'existe pas de théorie générale du raisonnement par induction (Norton, 2010), et que chaque domaine scientifique possède ses propres critères méthodologiques, en particulier sur la question de la reproductibilité. La sociologue Knorr-Cetina montre en observant des physiciens des particules et des imunologistes que différents domaines scientifiques possèdent différentes "**cultures épistémiques**", battant en brèche l'idée qu'il existerait UNE méthode scientifique (Knorr-Cetina, 1999). C'est que les philosophes des sciences nomment "the disunity of science". Dans le même ordre d'idée, Collins, en invoquant le "experimenter's regress" énonce que la question de la reproductibilité doit d'abord résoudre le problème du consensus de ce que constitue le même "espace expérimental" qui va définir sur ce quoi un groupe de chercheurs peut se mettre d'accord quant à la validité des expériences. A l'intérieur de cet espace, un consensus sur la reproductibilité peut émerger, mais il ne serra jamais universel. 
Dans "How experiments end", Galison oppose deux catégories de scientifiques dans le même domaine de la physique des particules : ceux qui basent leur confiance dans les trajectoires effectivement observées dans les chambres à bulle et ceux qui ont plus confiance dans le traitement statistique Monte Carlo et la répétition des calculs ("anything can happen once"). On est là en présence d'une cohabitation de légitimités expérimentale et statistique (voire computationnelle) avec des stratégies différentes de définition de ce qui est fiable à l'intérieur d'un même champ scientifique (Galison, 1987).

Généalogie
----------
Pourtant, la reproductibilité comme norme, comme exigence, est souvent rhétoriquement liée à l'expérimentation, au discours de l'expérimentation. Les techniques de Boyle (voir chapitre 1) pour convaincre et acquérir une légitimité sont à l'origine de la fondation de la Royal Society et du concept de publication, et sont devenues l'archétype de la reproductibilité universelle telle qu'elle est fantasmée. C'est peut-être cette légitimation de l'expérience qui est à la base du discours des scientifiques sur le fait que la reproductibilité doit être le "golden standard" en science. Du coup, la reproductibilité computationnelle ne vient, chronologiquement, qu'après.

Et on peut même se poser la question de savoir si une part de la "crise de la reproductibilité" n'est pas liée à la place importante que les outils computationnels et statistiques ont pris dans les sciences contemporaines. N'y aurait-il pas un soupçon de non-reproductibilité de l'expérience à cause des traitements statistiques et computationnels appliqués aux "données" expérimentales, dans la même veine que la citation apocryphe de Churchill **"**je ne crois aux statistiques que j'ai moi même falsifiées". Les controverses des ondes gravitationnlles dans les années 70 montrent déjà un déplacement du terrain de la reproduction du dispositif expérimental lui même vers son traitement statistique. La controverse s'est terminé en 2015 quand les traitements statistiques ont enfin fait consensus, et une des conclusions de Collins est que la validité statistique est grandement dépendante du domaine à laquelle on l'applique (Collins, 2016).

Si la reproductibilité statistique est grandement discutée (voir chapitre 4), il existe aussi une part de (problème de) reproductibilité qui est computationnelle sans pour autant être statistique, et elle a tendance à être parfois invisibilisée par ou confondue avec le statistique. Que ça soit en traitement de données, en modélisation, en informatique ou même dans quasiment tous les appareils électroniques de l'instrumentation, la computation intervient  dans des recoins de la science sans même que le scientifique s'en rende parfois compte.

D'ailleurs, le calcul computationnel est souvent réduit, y compris par ses acteurs mêmes, à l'activité de traitement de données par le calcul, ce qui favorise la confusion entre computationnel et statistique. De fait, le computationnel est vu comme "ce qui traite les données" : *Computer scientist Jon Claerbout coined the term and associated it with a software platform and set of procedures that permit the reader of a paper to see the entire processing trail from the raw data and code to figures and tables (Goodman 2016). *Pourtant, même s'ils sont interpénétrés, le statistique et le computationnel ne posent pas les mêmes problèmes de reproductibilité.

En poussant cette idée, il y aussi l'évolution de l'expérimentation du type "*single experimenter who builds his own apparatus and who knows its foibles and idiosyncrasies*" vers le "*research team with a marked division of labour and a hierarchical management structure*" (Bloor 1991 reviewant Galison) et j'ajouterais : l'instrument avec ses théories embarquées (Reinhardt, citant Bachelard) est aussi un objet pour lequel la confiance peut être basée sur des considérations commerciales (la garantie d'un instrument est fourni par le constructeur qui est une entreprise) et qui contient de plus en plus de computationnel (en particulier des logiciels de traitement du signal qui sont propriétaires puisque faisant partie de l'instrument industriel). Les spectroscopies sont particulièrement dans ce cas, et la RMN est l'exemple le plus cité (Reinhardt, 2006)

Caractéristiques de la reproductibilité computationnelle
--------------------------------------------------------
La reproductibilité computationnelle souffre elle d'un déficit de reconnaissance "grand public" : beaucoup en ont une image superficielle d'infaillibilité "2+2=4 est tout le temps vrai" et pourtant elle a eu aussi son moment de "crise grand pubic" avec le climategate suivi du Science Code Manifesto en 2011. A cette occasion, la révélation d'emails de chercheurs en science du climat avaient semé la panique dans la communauté dont la crédibilité est un enjeu hautement politique. Le point le plus controversé de ce climategate était l'utilisation de *tricks* dans la programmation des modèles (en pratique, les emails en question mentionnaient des commentaires de lignes de codes incluant des subroutines appelées "tricks"), ce qui a abouti à une prise de conscience des problèmes posés par la programmation scientifique, et à l'élaboration du Science Code Manifesto en 2011 (Bailey, 2011).
Parmi les caractéristiques de reproductibilité computationnelle évoquées dans ce booksprint, la plupart concerne le software. Comme la curation de données, le travail de programmation (et non seulement de programmation mais aussi de compilation, distribution, politique de licence...) par un chercheur n'est pas récompensé par la publication (sauf s'il s'agit de son activité de recherche elle même) (Hocquet Wieber 2017). De fait, une grosse partie de l'activité computationnelle est réalisée par des scientifiques dont ce n'est pas le métier : ni dans le coding, ni dans le management, ni dans la diffusion et le licensing. C'est la différence entre la computing science (qui produit et publie des programmes) et la computational (qui utilise des programmes dans son activité). Par ailleurs, l'industrie du software en général est elle même un domaine "en crise" depuis les années 60 (Ensmenger, 2011) : Contrairement au hardware qui est de plus en plus performant (voir la loi de Moore), le software est toujours en retard, toujours plus cher que prévu, à l'interopérabilité toujours plus compliquée, et à la stabilité et la cohérence jamais achevées : La "software crisis" est un art de vivre.
Même si la définition et l'organisation de bonnes pratiques sont des préoccupations des chercheurs (Rougier, 2018) et que ses bonnes pratiques sont souvent inspirées par les "libertés fondamentales du logiciel libre" établisssant en cela une connexion directe entre principes du logiciel libre et open science, Le logiciel scientifique possède une existence en pratique parfois sujette a des tensions entre normes académiques et normes commerciales, liées entre autres à cette absence de récompense : commercialisation de packages (éventuellement encouragées par les politiques de "technology transfer" des universités) (Hocquet Wieber 2017), ou inversement, énorme investissement en énergie et temps pour produire un logiciel libre, incapacité à imaginer un "business model" qui satisfasse à des éxigences épistémiques de trnasparence, protection du code par peur de la compétition, mais aussi par souci de stabilité du logiciel, licences variables selon les utilisateurs académiques ou industriels, bricolage de paramètres dans les modèles en fonction des utilisateurs (Wieber Hocquet, 2018). 
